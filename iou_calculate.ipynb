{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "labeled-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "from transglot.models.listener import *\n",
    "from transglot.simple_utils import unpickle_data\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import hydra\n",
    "import omegaconf\n",
    "\n",
    "top_data_dir = 'data/main_data_for_chairs'\n",
    "img_dir = osp.join(top_data_dir,\"images/shapenet/03001627\")\n",
    "data_name = 'game_data.pkl'\n",
    "game_data, word_to_int, int_to_word, int_to_sn_model, sn_model_to_int, sorted_sn_models = \\\n",
    "    unpickle_data(osp.join(top_data_dir, data_name))\n",
    "vocab_size=len(int_to_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "religious-nickel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique geometries in train/test/val 3145 393 393\n"
     ]
    }
   ],
   "source": [
    "#git: before reduce attention dimension by 2\n",
    "outputs_top_dir = \"outputs\"\n",
    "ver_date_dir = \"pretrained\"\n",
    "\n",
    "# Automatically select best ckpt #\n",
    "best_acc = -1\n",
    "for file in os.listdir(osp.join(outputs_top_dir, f\"checkpoints/{ver_date_dir}\")):\n",
    "    if file[-4:] != \"ckpt\" or file == \"last.ckpt\":\n",
    "        continue\n",
    "    val_acc = float(file[-9:-5])\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        ckpt_path = osp.join(outputs_top_dir, f\"checkpoints/{ver_date_dir}/{file}\")\n",
    "#################################\n",
    "\n",
    "# get hyper parameters #\n",
    "hparams_path = osp.join(outputs_top_dir,\"logs\", ver_date_dir, \"hparams.yaml\")\n",
    "hparams = omegaconf.OmegaConf.load(hparams_path)\n",
    "########################\n",
    "\n",
    "listener = Transglot.load_from_checkpoint(ckpt_path, hparams=hparams).cuda()\n",
    "listener.eval()\n",
    "for p in listener.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "downtown-diabetes",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique geometries in train/test/val 3145 393 393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b11950f39f4eb584954f9410c01d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 78.01102447509766, 'test_loss': 0.660237729549408}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 78.01102447509766, 'test_loss': 0.660237729549408}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1,\n",
    "                    checkpoint_callback=False,\n",
    "                    logger=False)\n",
    "trainer.test(listener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "handled-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a set of chairs in the test dataset\n",
    "listener.eval()\n",
    "test_ds = listener.test_ds\n",
    "int2sn = int_to_sn_model\n",
    "sn2int = sn_model_to_int\n",
    "all_test_chairs = set()\n",
    "for i in range(len(test_ds)):\n",
    "    chairs, chairs_idx, targets, padded_token = test_ds[i]\n",
    "    sn_id1, sn_id2, sn_id3 = int2sn[chairs_idx[0]], int2sn[chairs_idx[1]], int2sn[chairs_idx[2]]\n",
    "    if sn_id1 not in all_test_chairs:\n",
    "        all_test_chairs.add(sn_id1)\n",
    "    if sn_id2 not in all_test_chairs:\n",
    "        all_test_chairs.add(sn_id2)\n",
    "    if sn_id3 not in all_test_chairs:\n",
    "        all_test_chairs.add(sn_id3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "seeing-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract chairs that exists in shapenet_seg dataset\n",
    "all_test_chairs = list(all_test_chairs)\n",
    "test_chairs = []\n",
    "\n",
    "# You can download Shapenet with part annotations from code below.\n",
    "# wget https://shapenet.cs.stanford.edu/ericyi/shapenetcore_partanno_v0.zip\n",
    "dir_path = \"/home/ubuntu/datasets/full_shapenet_seg/03001627\" \n",
    "for i in all_test_chairs:\n",
    "    path = osp.join(dir_path, f\"{i}.txt\")\n",
    "    if osp.exists(path):\n",
    "        test_chairs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reverse-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(sn_id, sentence=\"leg\", threshold=0.5):\n",
    "     # 12: back |13: seat | 14: leg | 15: arm\n",
    "    \n",
    "    ###### Load & break_up pc and label #############\n",
    "    pc = np.loadtxt(osp.join(dir_path,f\"{sn_id}.txt\"))\n",
    "    label = pc[:, -1]\n",
    "    back_label = (label == 12.)\n",
    "    seat_label = (label == 13.)\n",
    "    leg_label = (label == 14.)\n",
    "    arm_label = (label == 15.)\n",
    "    \n",
    "    pc = pc[:, :3]\n",
    "    #################################################\n",
    "    \n",
    "    ########### make network's input         ############\n",
    "    pc_input = torch.tensor(pc).float().unsqueeze(0).cuda()\n",
    "    \n",
    "    token = sentence.split(\" \")\n",
    "    token = np.array([word_to_int[token] for token in token])\n",
    "    pad_cnt = 34 - len(token)\n",
    "    padded_token = np.pad(token, (0, pad_cnt), \"constant\", constant_values=0)\n",
    "    padded_token = torch.tensor(padded_token).unsqueeze(0).cuda()\n",
    "    ###################################################\n",
    "    \n",
    "    ########### extract point feature & language feature ############\n",
    "    p_f = listener.pc_encoder(pc_input)\n",
    "    l_f = listener.language_encoder_attn(padded_token)[0]\n",
    "    #################################################################\n",
    "    \n",
    "    ######## get attention & binary #######\n",
    "    attn_f, attn_weight = listener.cross_attn_layers[0](l_f.unsqueeze(1), p_f, p_f)\n",
    "    attn_map = attn_weight.squeeze().detach().cpu().numpy()\n",
    "    minv = attn_map.min(axis=0)\n",
    "    maxv = attn_map.max(axis=0)\n",
    "    attn_map = (attn_map - minv) / (maxv - minv)\n",
    "    attn_map = np.where(attn_map > threshold, 1, 0)\n",
    "    ######################################\n",
    "    \n",
    "    def get_iou(pred, gt):\n",
    "        intersect = np.sum(np.logical_and(pred, gt))\n",
    "        union = np.sum(np.logical_or(pred, gt))\n",
    "        iou = intersect / (union + 1e-8)\n",
    "        return iou\n",
    "    \n",
    "    back_iou = 100*get_iou(attn_map, back_label) if back_label.sum() > 0 else float(\"NaN\")\n",
    "    seat_iou = 100*get_iou(attn_map, seat_label) if seat_label.sum() > 0 else float(\"NaN\")\n",
    "    leg_iou = 100*get_iou(attn_map, leg_label) if leg_label.sum() > 0 else float(\"NaN\")\n",
    "    arm_iou = 100*get_iou(attn_map, arm_label) if arm_label.sum() > 0 else float(\"NaN\")\n",
    "    \n",
    "    return back_iou, seat_iou, leg_iou, arm_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tamil-tulsa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 finish\n",
      "100 finish\n",
      "200 finish\n",
      "300 finish\n",
      "400 finish\n",
      "500 finish\n",
      "600 finish\n",
      "700 finish\n"
     ]
    }
   ],
   "source": [
    "from math import isnan\n",
    "\n",
    "# iou[\"back\"][\"leg\"] = iou of leg, given back label.\n",
    "iou = dict(back=dict(back=[],seat=[],leg=[],arm=[]),\n",
    "           seat=dict(back=[],seat=[],leg=[],arm=[]),\n",
    "           leg=dict(back=[],seat=[],leg=[],arm=[]),\n",
    "           arm=dict(back=[],seat=[],leg=[],arm=[])) \n",
    "\n",
    "for (i, sn_id) in enumerate(test_chairs):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"{i} finish\")\n",
    "    for label in [\"back\", \"seat\", \"leg\", \"arm\"]:\n",
    "        back, seat, leg, arm = calculate_iou(sn_id, label)\n",
    "        if not isnan(back):\n",
    "            iou[label][\"back\"].append(back)\n",
    "        if not isnan(seat):\n",
    "            iou[label][\"seat\"].append(seat)\n",
    "        if not isnan(leg):\n",
    "            iou[label][\"leg\"].append(leg)\n",
    "        if not isnan(arm):\n",
    "            iou[label][\"arm\"].append(arm)\n",
    "\n",
    "for i in [\"back\", \"seat\", \"leg\", \"arm\"]:\n",
    "    for j in [\"back\", \"seat\", \"leg\", \"arm\"]:\n",
    "        iou[i][j] = sum(iou[i][j]) / len(iou[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "boolean-arkansas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given back\n",
      "back: 20.35 | seat: 0.44 | leg: 0.14 | arm: 1.45 | \n",
      "Given seat\n",
      "back: 40.21 | seat: 20.87 | leg: 3.99 | arm: 7.74 | \n",
      "Given leg\n",
      "back: 1.35 | seat: 1.49 | leg: 14.93 | arm: 0.84 | \n",
      "Given arm\n",
      "back: 0.34 | seat: 7.54 | leg: 3.60 | arm: 4.85 | \n"
     ]
    }
   ],
   "source": [
    "for i in [\"back\", \"seat\", \"leg\", \"arm\"]:\n",
    "    print(f\"Given {i}\")\n",
    "    for j in [\"back\", \"seat\", \"leg\", \"arm\"]:\n",
    "        print(f\"{j}: {iou[i][j]:.2f}\", end=\" | \")\n",
    "        if j == \"arm\":\n",
    "            print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}